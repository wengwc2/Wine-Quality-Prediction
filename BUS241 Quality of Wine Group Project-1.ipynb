{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Final Project Outline \n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* Visualization on Dataset \n",
    "* Linear Regression\n",
    "* Polynomial Regression \n",
    "* Regularization \n",
    "    * Grid search\n",
    "* Classication \n",
    "    * Logistic \n",
    "    * KNN  \n",
    "    * Support Vector \n",
    "* Decision Tree \n",
    "    * Classification Tree\n",
    "    * Regression Tree\n",
    "    * BAGG \n",
    "    * Random Forest \n",
    "    * Boosting\n",
    "\n",
    "The data was taken from the Kaggle competition with the wine quality dataset\n",
    "\n",
    "The dataset consists of parameters that determines the win'e different aspect as well as the numerical evaluation of the wine quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description taken from Kaggle:\n",
    "### Input variables (based on physicochemical tests):\n",
    "    1 - fixed acidity\n",
    "    2 - volatile acidity\n",
    "    3 - citric acid\n",
    "    4 - residual sugar\n",
    "    5 - chlorides\n",
    "    6 - free sulfur dioxide\n",
    "    7 - total sulfur dioxide\n",
    "    8 - density\n",
    "    9 - pH\n",
    "    10 - sulphates\n",
    "    11 - alcohol\n",
    "    Output variable (based on sensory data):\n",
    "    12 - quality (score between 0 and 10)\n",
    "\n",
    " ## General Note about the Data\n",
    "    1- File Reader to 'Rule Engine Node' to turn the 10 point scale to dichtome variable (good wine and rest), the code to put in the rule engine is something like this:\n",
    "        $quality$ > 6.5 => \"good\"\n",
    "        TRUE => \"bad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Goal:\n",
    "We transformed the column for wine quality into binary and thus create both binary y and also numerical y for the different models.\n",
    "\n",
    "\n",
    "We designated two sets of Y in this case\n",
    "\n",
    "1. The first one is numerical where it measures the wine quality from a scale from 2 to 8\n",
    "\n",
    "\n",
    "2. The second one is a binary where it measures the wine quality in simple 0 and 1 where 1 is designated for good wine quality (>6.5)\n",
    "\n",
    "We are targeted to conduct research to investigate classification vs regression\n",
    "\n",
    "We are looking to examine which method provide the best result. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Preperation and Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "87c7b371-53b1-4d4d-bfbd-373d2b84b33a",
    "_uuid": "da5343fb3f6b3942909c94bf8e2add04fd3ff1a3",
    "execution": {
     "iopub.execute_input": "2022-04-26T21:04:41.969539Z",
     "iopub.status.busy": "2022-04-26T21:04:41.968859Z",
     "iopub.status.idle": "2022-04-26T21:04:41.984235Z",
     "shell.execute_reply": "2022-04-26T21:04:41.983312Z",
     "shell.execute_reply.started": "2022-04-26T21:04:41.969471Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing required packages. hello\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Importing Classification / Model Selection Tools\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T21:23:31.615684Z",
     "iopub.status.busy": "2022-04-26T21:23:31.615342Z",
     "iopub.status.idle": "2022-04-26T21:23:31.629325Z",
     "shell.execute_reply": "2022-04-26T21:23:31.628614Z",
     "shell.execute_reply.started": "2022-04-26T21:23:31.615634Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T20:55:19.943211Z",
     "iopub.status.busy": "2022-04-26T20:55:19.942813Z",
     "iopub.status.idle": "2022-04-26T20:55:19.953285Z",
     "shell.execute_reply": "2022-04-26T20:55:19.952616Z",
     "shell.execute_reply.started": "2022-04-26T20:55:19.943145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "704f4830-5804-436d-9b78-6ca00f5ae510",
    "_uuid": "af141503385967f92d409c5e111e2724b4c9636f",
    "execution": {
     "iopub.execute_input": "2022-04-26T20:49:39.303226Z",
     "iopub.status.busy": "2022-04-26T20:49:39.302933Z",
     "iopub.status.idle": "2022-04-26T20:49:39.311935Z",
     "shell.execute_reply": "2022-04-26T20:49:39.311028Z",
     "shell.execute_reply.started": "2022-04-26T20:49:39.303181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "#Information about the data columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T21:23:33.164458Z",
     "iopub.status.busy": "2022-04-26T21:23:33.163849Z",
     "iopub.status.idle": "2022-04-26T21:23:33.179877Z",
     "shell.execute_reply": "2022-04-26T21:23:33.178933Z",
     "shell.execute_reply.started": "2022-04-26T21:23:33.164367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wine\n",
       "bad     7475\n",
       "good    1537\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_quality = pd.cut(df['quality'],\n",
    "bins = [0, 6.5, 8],\n",
    "labels=['bad', 'good'])\n",
    "dict_binned_quality = {'wine': binned_quality}\n",
    "df['wine'] = pd.DataFrame(dict_binned_quality)\n",
    "df.groupby('wine').quality.sum()\n",
    "#I changed the name from 'bin_q' to 'wine' so the column name is more clear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T21:23:35.254753Z",
     "iopub.status.busy": "2022-04-26T21:23:35.254382Z",
     "iopub.status.idle": "2022-04-26T21:23:35.442872Z",
     "shell.execute_reply": "2022-04-26T21:23:35.442166Z",
     "shell.execute_reply.started": "2022-04-26T21:23:35.254701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), [Text(0, 0, 'bad'), Text(1, 0, 'good')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('wine').quality.sum().plot(kind = 'bar', figsize = (18, 9))\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T21:23:38.69251Z",
     "iopub.status.busy": "2022-04-26T21:23:38.691999Z",
     "iopub.status.idle": "2022-04-26T21:23:38.712191Z",
     "shell.execute_reply": "2022-04-26T21:23:38.711597Z",
     "shell.execute_reply.started": "2022-04-26T21:23:38.692427Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality wine  \n",
       "0      9.4        5  bad  \n",
       "1      9.8        5  bad  \n",
       "2      9.8        5  bad  \n",
       "3      9.8        6  bad  \n",
       "4      9.4        5  bad  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T21:23:41.966437Z",
     "iopub.status.busy": "2022-04-26T21:23:41.965882Z",
     "iopub.status.idle": "2022-04-26T21:23:41.9893Z",
     "shell.execute_reply": "2022-04-26T21:23:41.988677Z",
     "shell.execute_reply.started": "2022-04-26T21:23:41.96639Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['wine'], drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T21:23:56.991191Z",
     "iopub.status.busy": "2022-04-26T21:23:56.99065Z",
     "iopub.status.idle": "2022-04-26T21:23:57.015779Z",
     "shell.execute_reply": "2022-04-26T21:23:57.014971Z",
     "shell.execute_reply.started": "2022-04-26T21:23:56.991143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>wine_good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.089</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.114</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.176</td>\n",
       "      <td>52.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0             7.4             0.700         0.00             1.9      0.076   \n",
       "1             7.8             0.880         0.00             2.6      0.098   \n",
       "2             7.8             0.760         0.04             2.3      0.092   \n",
       "3            11.2             0.280         0.56             1.9      0.075   \n",
       "4             7.4             0.700         0.00             1.9      0.076   \n",
       "5             7.4             0.660         0.00             1.8      0.075   \n",
       "6             7.9             0.600         0.06             1.6      0.069   \n",
       "7             7.3             0.650         0.00             1.2      0.065   \n",
       "8             7.8             0.580         0.02             2.0      0.073   \n",
       "9             7.5             0.500         0.36             6.1      0.071   \n",
       "10            6.7             0.580         0.08             1.8      0.097   \n",
       "11            7.5             0.500         0.36             6.1      0.071   \n",
       "12            5.6             0.615         0.00             1.6      0.089   \n",
       "13            7.8             0.610         0.29             1.6      0.114   \n",
       "14            8.9             0.620         0.18             3.8      0.176   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                  25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                  15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                  17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                  11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                  13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                  15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                  15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                   9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                  17.0                 102.0   0.9978  3.35       0.80   \n",
       "10                 15.0                  65.0   0.9959  3.28       0.54   \n",
       "11                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "12                 16.0                  59.0   0.9943  3.58       0.52   \n",
       "13                  9.0                  29.0   0.9974  3.26       1.56   \n",
       "14                 52.0                 145.0   0.9986  3.16       0.88   \n",
       "\n",
       "    alcohol  quality  wine_good  \n",
       "0       9.4        5          0  \n",
       "1       9.8        5          0  \n",
       "2       9.8        5          0  \n",
       "3       9.8        6          0  \n",
       "4       9.4        5          0  \n",
       "5       9.4        5          0  \n",
       "6       9.4        5          0  \n",
       "7      10.0        7          1  \n",
       "8       9.5        7          1  \n",
       "9      10.5        5          0  \n",
       "10      9.2        5          0  \n",
       "11     10.5        5          0  \n",
       "12      9.9        5          0  \n",
       "13      9.1        5          0  \n",
       "14      9.2        5          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T21:31:14.650105Z",
     "iopub.status.busy": "2022-04-26T21:31:14.649788Z",
     "iopub.status.idle": "2022-04-26T21:31:14.657366Z",
     "shell.execute_reply": "2022-04-26T21:31:14.656344Z",
     "shell.execute_reply.started": "2022-04-26T21:31:14.650047Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('quality', axis = 1)\n",
    "X =X.drop('wine_good', axis = 1)\n",
    "\n",
    "# df['quality'] is numerical df['wine_good'] is binary\n",
    "#y = df['quality']\n",
    "y = df['wine_good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T21:31:40.990239Z",
     "iopub.status.busy": "2022-04-26T21:31:40.989683Z",
     "iopub.status.idle": "2022-04-26T21:31:41.008664Z",
     "shell.execute_reply": "2022-04-26T21:31:41.007901Z",
     "shell.execute_reply.started": "2022-04-26T21:31:40.990188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: wine_good, dtype: uint8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "testSize = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=42)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24657634122966113\n",
      "0.22168857993237603\n"
     ]
    }
   ],
   "source": [
    "nmc = 500\n",
    "line=LinearRegression()\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=.5)\n",
    "CVInfo = cross_validate(line, X, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.045829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>0.104899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>0</td>\n",
       "      <td>0.157460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>0</td>\n",
       "      <td>0.191653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0</td>\n",
       "      <td>0.396788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.008291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.354956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "803        0   0.004529\n",
       "124        0  -0.045829\n",
       "350        0   0.104899\n",
       "682        0   0.010764\n",
       "1326       0   0.157460\n",
       "...      ...        ...\n",
       "1565       0   0.191653\n",
       "327        0   0.396788\n",
       "254        0   0.017353\n",
       "322        0  -0.008291\n",
       "1160       1   0.354956\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.fit(X_train, y_train)\n",
    "y_pred_linear = line.predict(X_test)\n",
    "Linear = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_linear})\n",
    "Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23401826887366298\n",
      "0.21444063434188415\n"
     ]
    }
   ],
   "source": [
    "# Run Ridge on original data\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "nmc = 500\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=.5)\n",
    "ridge = Ridge(alpha=5.0)\n",
    "CVInfo = cross_validate(ridge, X, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.046369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>0.104570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>0</td>\n",
       "      <td>0.157720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>0</td>\n",
       "      <td>0.191137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0</td>\n",
       "      <td>0.395413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.007814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.354118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "803        0   0.005183\n",
       "124        0  -0.046369\n",
       "350        0   0.104570\n",
       "682        0   0.011979\n",
       "1326       0   0.157720\n",
       "...      ...        ...\n",
       "1565       0   0.191137\n",
       "327        0   0.395413\n",
       "254        0   0.017866\n",
       "322        0  -0.007814\n",
       "1160       1   0.354118\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "Ridge=pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_ridge})\n",
    "Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.874120406567631\n",
      "Test Score:\n",
      "0.84375\n",
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "sgdc = SGDClassifier(loss=\"log\",penalty=\"l2\",max_iter=500, tol=1e-3)\n",
    "sgdc.fit(X_train, y_train)\n",
    "score = sgdc.score(X_train, y_train)\n",
    "print(\"Score: \", score)\n",
    "print(\"Test Score:\")\n",
    "print(sgdc.score(X_test,y_test))\n",
    "\n",
    "y_pred = sgdc.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Best Score:  0.8688113719255588\n",
      "Best Params:  {'C': 0.1, 'class_weight': {1: 0.5, 0: 0.5}, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l1', 'l2'] \n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] \n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}] \n",
    "solver = ['liblinear', 'saga'] \n",
    "param_grid = dict(penalty=penalty, \n",
    "C=C, \n",
    "class_weight=class_weight, \n",
    "solver=solver) \n",
    "logistic = LogisticRegression() \n",
    "grid = GridSearchCV(estimator=logistic, \n",
    "param_grid=param_grid, \n",
    "scoring='roc_auc', \n",
    "verbose=1, \n",
    "n_jobs=-1) \n",
    "grid_result = grid.fit(X_train, y_train) \n",
    "print('Best Score: ', grid_result.best_score_) \n",
    "print('Best Params: ', grid_result.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8641777221526908\n",
      "0.8644025000000001\n",
      "Accuracy: 0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is best model for SDG\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "best_model2 = grid_result.best_estimator_\n",
    "\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(best_model2, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))\n",
    "\n",
    "y_pred = best_model2.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Stardardization is not needed when dealing with non-regularized regresssions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score for Logistic Regression:  0.87961\n",
      "Test Score for Logistic Regression:  0.8826989157631361\n"
     ]
    }
   ],
   "source": [
    "# Setup nmc and Logistic Regression\n",
    "Xs=X.copy()\n",
    "nmc = 250\n",
    "lr = LogisticRegression(penalty = \"none\", solver = \"lbfgs\", max_iter = 1000)\n",
    "\n",
    "# Running 250 Monte Carlo cross-validation\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "CVInfo = cross_validate(lr, Xs, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(\"Train Score for Logistic Regression: \", np.mean(CVInfo['test_score']))\n",
    "print(\"Test Score for Logistic Regression: \", np.mean(CVInfo['train_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       273\n",
      "           1       0.57      0.28      0.37        47\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.73      0.62      0.65       320\n",
      "weighted avg       0.84      0.86      0.84       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report and Scores\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       273\n",
      "           1       0.57      0.28      0.37        47\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.73      0.62      0.65       320\n",
      "weighted avg       0.84      0.86      0.84       320\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       273\n",
      "           1       0.57      0.28      0.37        47\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.73      0.62      0.65       320\n",
      "weighted avg       0.84      0.86      0.84       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report and Scores\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, pred_lr))\n",
    "# Classification Report and Scores\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, pred_lr))\n",
    "# part 2: K-Nearest Neighbor Regression\n",
    "# Note: Standardization is needed for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: K-Nearest Neighbor Regression\n",
    "Note: Standardization is needed for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank_test_score  mean_test_score param_knn__n_neighbors\n",
      "0                4          0.87180                      5\n",
      "1                2          0.87662                     10\n",
      "2                1          0.87858                     25\n",
      "3                3          0.87566                     50\n",
      "4                5          0.87077                    100\n",
      "5                6          0.86454                    250\n",
      "-------------------------------------------------------------------------------------\n",
      "best param: {'knn__n_neighbors': 25}\n",
      "best model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('knn', KNeighborsClassifier(n_neighbors=25))])\n",
      "best test score: 0.8785799999999999\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline model with Monte Carlo set to 250\n",
    "\n",
    "fullModel = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid={'knn__n_neighbors':[5, 10, 25, 50, 100, 250]}\n",
    "shuffle_split = ShuffleSplit(test_size=0.25, n_splits=250)\n",
    "grid_search = GridSearchCV(fullModel,param_grid,cv=shuffle_split,\n",
    "                              return_train_score=True,n_jobs=-1)\n",
    "grid_search.fit(Xs,y)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results[['rank_test_score','mean_test_score','param_knn__n_neighbors']])\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"best param:\",grid_search.best_params_)\n",
    "print(\"best model:\",grid_search.best_estimator_)\n",
    "print(\"best test score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: \n",
      "train score:  0.8847005838198498\n",
      "test score:  0.87712\n"
     ]
    }
   ],
   "source": [
    "# Save the best parameters from grid search as the best model\n",
    "best_knnmodel = grid_search.best_estimator_\n",
    "\n",
    "# Re-run the best model using cross validation\n",
    "nmc = 250\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "CVInfo = cross_validate(best_knnmodel, Xs, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(\"Best Model: \")\n",
    "print(\"train score: \",np.mean(CVInfo['train_score']))\n",
    "print(\"test score: \",np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       273\n",
      "           1       0.46      0.23      0.31        47\n",
      "\n",
      "    accuracy                           0.85       320\n",
      "   macro avg       0.67      0.59      0.61       320\n",
      "weighted avg       0.82      0.85      0.83       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report and Scores\n",
    "best_knnmodel.fit(X_train, y_train)\n",
    "pred_knn = best_knnmodel.predict(X_test)\n",
    "print(classification_report(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       273\n",
      "           1       0.71      0.26      0.37        47\n",
      "\n",
      "    accuracy                           0.88       320\n",
      "   macro avg       0.80      0.62      0.65       320\n",
      "weighted avg       0.86      0.88      0.85       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic Support Vector Machines with default hyperparameters\n",
    "lsv = SVC()\n",
    "lsv.fit(X_train, y_train)\n",
    "pred_lsv = lsv.predict(X_test)\n",
    "\n",
    "# Classification Reprot for Basic LSV with default hyperparameters\n",
    "print(classification_report(y_test, pred_lsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rank_test_score  mean_test_score param_C param_kernel param_gamma\n",
      "39                1          0.88300     0.9          rbf         0.6\n",
      "37                2          0.88275     0.9          rbf         0.5\n",
      "35                3          0.88025     0.9          rbf         0.4\n",
      "33                4          0.87800     0.9          rbf         0.3\n",
      "27                5          0.86900     0.8          rbf         0.4\n",
      "-------------------------------------------------------------------------------------\n",
      "best param: {'C': 0.8999999999999999, 'gamma': 0.6000000000000001, 'kernel': 'rbf'}\n",
      "best model: SVC(C=0.8999999999999999, gamma=0.6000000000000001)\n",
      "best test score: 0.883\n"
     ]
    }
   ],
   "source": [
    "# Incorprating Monte Carlo CV and grid search for 3 hyperparameters: C, kernel, gamma\n",
    "param_grid={'C': np.arange(0.5,1,0.1),\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'gamma': np.arange(0.3,0.7,0.1)}\n",
    "\n",
    "shuffle_split = ShuffleSplit(test_size=0.25, n_splits=10)\n",
    "grid_search = GridSearchCV(SVC(),param_grid,cv=shuffle_split,\n",
    "                              return_train_score=True,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(Xs,y)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results.sort_values(by = 'rank_test_score').head(5)\n",
    "print(results[['rank_test_score','mean_test_score','param_C','param_kernel','param_gamma']])\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"best param:\",grid_search.best_params_)\n",
    "print(\"best model:\",grid_search.best_estimator_)\n",
    "print(\"best test score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rank_test_score  mean_test_score param_C param_kernel param_gamma\n",
      "39                1          0.88300     0.9          rbf         0.6\n",
      "37                2          0.88275     0.9          rbf         0.5\n",
      "35                3          0.88025     0.9          rbf         0.4\n",
      "33                4          0.87800     0.9          rbf         0.3\n",
      "27                5          0.86900     0.8          rbf         0.4\n",
      "-------------------------------------------------------------------------------------\n",
      "best param: {'C': 0.8999999999999999, 'gamma': 0.6000000000000001, 'kernel': 'rbf'}\n",
      "best model: SVC(C=0.8999999999999999, gamma=0.6000000000000001)\n",
      "best test score: 0.883\n"
     ]
    }
   ],
   "source": [
    "print(results[['rank_test_score','mean_test_score','param_C','param_kernel','param_gamma']])\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"best param:\",grid_search.best_params_)\n",
    "print(\"best model:\",grid_search.best_estimator_)\n",
    "print(\"best test score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       273\n",
      "           1       0.81      0.36      0.50        47\n",
      "\n",
      "    accuracy                           0.89       320\n",
      "   macro avg       0.85      0.67      0.72       320\n",
      "weighted avg       0.89      0.89      0.88       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run and Classification report for best model\n",
    "lsv = SVC(C=0.9, gamma=0.6, kernel = 'rbf')\n",
    "lsv.fit(X_train, y_train)\n",
    "pred_lsv = lsv.predict(X_test)\n",
    "\n",
    "# Classification Reprot for Basic LSV with default hyperparameters\n",
    "print(classification_report(y_test, pred_lsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999736170181\n",
      "-109012.50265192133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=4,include_bias=False)\n",
    "Xpoly = poly.fit_transform(X)\n",
    "X_train_p, X_test_p, y_train, y_test = train_test_split(Xpoly, y, test_size = 0.2, random_state = 42)\n",
    "nmc = 500\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=.5)\n",
    "\n",
    "CVInfo = cross_validate(line, Xpoly, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.059117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>7.822697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.347188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.145030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.004994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0</td>\n",
       "      <td>2.334331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.298940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "803        0  -1.059117\n",
       "124        0   7.822697\n",
       "350        0  -3.347188\n",
       "682        0  -2.145030\n",
       "1326       0   0.003979\n",
       "...      ...        ...\n",
       "1259       0  -0.004994\n",
       "1295       0  -0.000716\n",
       "1155       0   0.007686\n",
       "963        0   2.334331\n",
       "704        0  -0.298940\n",
       "\n",
       "[320 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.fit(X_train_p, y_train)\n",
    "y_pred_poly = line.predict(X_test_p)\n",
    "poly=pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_poly})\n",
    "poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-0.22349154073498398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "np.random.seed(42)\n",
    "nmc = 100\n",
    "testSize = 0.5\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(tree, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree with Grid Search for Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34901588236718595\n",
      "0.16693225458925848\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "fullModel = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"tree\", DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "# set up dictionary for grid search\n",
    "param_grid={'tree__max_depth': [1.,2.,3.,4.,5.,6.,7.,8.,9.,10.]}\n",
    "# set up cross-validation shuffles\n",
    "shuffle_split = ShuffleSplit(test_size=0.25, n_splits=100)\n",
    "# set up search\n",
    "grid_search=GridSearchCV(fullModel,param_grid,cv=shuffle_split,return_train_score=True,n_jobs=-1)\n",
    "# implement search\n",
    "np.random.seed(42)\n",
    "grid_search.fit(X_train,y_train)\n",
    "# This is best model\n",
    "best_model = grid_search.best_estimator_\n",
    "nmc = 100\n",
    "testSize = 0.5\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(best_model, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier with Grid Search of Max Depth and N_Estimators (Tree Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=100, random_state=None, test_size=0.25, train_size=None),\n",
       "             estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('tree', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tree__max_depth': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0,\n",
       "                                             8.0, 9.0, 10.0],\n",
       "                         'tree__n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "fullModel = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"tree\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# set up dictionary for grid search\n",
    "param_grid={'tree__max_depth': [1.,2.,3.,4.,5.,6.,7.,8.,9.,10.],'tree__n_estimators': [1,2,3,4,5,6,7,8,9,10]}\n",
    "# set up cross-validation shuffles\n",
    "shuffle_split = ShuffleSplit(test_size=0.25, n_splits=100)\n",
    "# set up search\n",
    "grid_search=GridSearchCV(fullModel,param_grid,cv=shuffle_split,return_train_score=True,n_jobs=-1)\n",
    "# implement search\n",
    "np.random.seed(42)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'tree__max_depth': 10.0, 'tree__n_estimators': 9}\n",
      "best model: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('tree',\n",
      "                 RandomForestClassifier(max_depth=10.0, n_estimators=9))])\n",
      "best test score: 0.8981562499999999\n"
     ]
    }
   ],
   "source": [
    "# Print best params and model\n",
    "print(\"best param:\",grid_search.best_params_)\n",
    "print(\"best model:\",grid_search.best_estimator_)\n",
    "print(\"best test score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880600750938673\n",
      "0.8890375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is best model\n",
    "best_model = grid_search.best_estimator_\n",
    "nmc = 100\n",
    "testSize = 0.5\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(best_model, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874902267396404\n",
      "0.903125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "bag_clf = BaggingClassifier(best_model,n_estimators=100,bootstrap=True,max_samples=1.,random_state=40)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_hat_train = bag_clf.predict(X_train)\n",
    "y_hat = bag_clf.predict(X_test)\n",
    "print(accuracy_score(y_hat_train,y_train))\n",
    "print(accuracy_score(y_hat,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting with Grid Search with Learning_Rate, Max_Depth, and Tree Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8893874999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbclf = GradientBoostingClassifier(n_estimators=800,max_depth=10,learning_rate=0.2,random_state=42)\n",
    "nmc = 100\n",
    "testSize = 0.5\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(gbclf, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Best Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874902267396404\n",
      "0.903125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(best_model,n_estimators=100,bootstrap=True,max_samples=1.,random_state=40)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_hat_train = bag_clf.predict(X_train)\n",
    "y_hat = bag_clf.predict(X_test)\n",
    "print(accuracy_score(y_hat_train,y_train))\n",
    "print(accuracy_score(y_hat,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8568875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "testSize = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=testSize, random_state=42)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "np.random.seed(42)\n",
    "nmc = 100\n",
    "testSize = 0.5\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(tree, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tree with Grid Search for Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8824906132665832\n",
      "0.8722125\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "fullModel = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"tree\", DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# set up dictionary for grid search\n",
    "param_grid={'tree__max_depth': [1.,2.,3.,4.,5.,6.,7.,8.,9.,10.]}\n",
    "# set up cross-validation shuffles\n",
    "shuffle_split = ShuffleSplit(test_size=0.25, n_splits=100)\n",
    "# set up search\n",
    "grid_search=GridSearchCV(fullModel,param_grid,cv=shuffle_split,return_train_score=True,n_jobs=-1)\n",
    "# implement search\n",
    "np.random.seed(42)\n",
    "grid_search.fit(X_train,y_train)\n",
    "# This is best model\n",
    "best_model = grid_search.best_estimator_\n",
    "nmc = 100\n",
    "testSize = 0.5\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(best_model, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Best Classsifier Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890742285237698\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(best_model,n_estimators=100,bootstrap=True,max_samples=1.,random_state=40)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_hat_train = bag_clf.predict(X_train)\n",
    "y_hat = bag_clf.predict(X_test)\n",
    "print(accuracy_score(y_hat_train,y_train))\n",
    "print(accuracy_score(y_hat,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier with Grid Search of Max Depth and N_Estimators (Tree Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=100, random_state=None, test_size=0.25, train_size=None),\n",
       "             estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('tree', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tree__max_depth': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0,\n",
       "                                             8.0, 9.0, 10.0],\n",
       "                         'tree__n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "fullModel = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"tree\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# set up dictionary for grid search\n",
    "param_grid={'tree__max_depth': [1.,2.,3.,4.,5.,6.,7.,8.,9.,10.],'tree__n_estimators': [1,2,3,4,5,6,7,8,9,10]}\n",
    "# set up cross-validation shuffles\n",
    "shuffle_split = ShuffleSplit(test_size=0.25, n_splits=100)\n",
    "# set up search\n",
    "grid_search=GridSearchCV(fullModel,param_grid,cv=shuffle_split,return_train_score=True,n_jobs=-1)\n",
    "# implement search\n",
    "np.random.seed(42)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'tree__max_depth': 10.0, 'tree__n_estimators': 10}\n",
      "best model: Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('tree',\n",
      "                 RandomForestClassifier(max_depth=10.0, n_estimators=10))])\n",
      "best test score: 0.8937666666666666\n"
     ]
    }
   ],
   "source": [
    "# Print best params and model\n",
    "print(\"best param:\",grid_search.best_params_)\n",
    "print(\"best model:\",grid_search.best_estimator_)\n",
    "print(\"best test score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885106382978723\n",
      "0.8913625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is best model\n",
    "best_model = grid_search.best_estimator_\n",
    "nmc = 100\n",
    "testSize = 0.5\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(best_model, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981651376146789\n",
      "0.895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(best_model,n_estimators=100,bootstrap=True,max_samples=1.,random_state=40)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_hat_train = bag_clf.predict(X_train)\n",
    "y_hat = bag_clf.predict(X_test)\n",
    "print(accuracy_score(y_hat_train,y_train))\n",
    "print(accuracy_score(y_hat,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8900375000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbclf = GradientBoostingClassifier(n_estimators=800,max_depth=10,learning_rate=0.2,random_state=42)\n",
    "nmc = 100\n",
    "testSize = 0.5\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=testSize)\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(gbclf, X, y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(gbclf,n_estimators=100,bootstrap=True,max_samples=1.,random_state=42,n_jobs=-1)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_hat_train = bag_clf.predict(X_train)\n",
    "y_hat = bag_clf.predict(X_test)\n",
    "print(accuracy_score(y_hat_train,y_train))\n",
    "print(accuracy_score(y_hat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the predicted result:\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Below is the predicted result:\\n{}\".format(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "(pd.Series(model.feature_importances_, index=X.columns)\n",
    "   .nlargest(4)\n",
    "   .plot(kind='barh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "## Feature Importance:\n",
    "\n",
    "1. We ran the feature analysis, where the column \"alcohol\" is the most crucial feature in this case to determine the y.\n",
    "\n",
    "\n",
    "2. Classification Algorithms work much better in terms of performance\n",
    "\n",
    "\n",
    "3. The regression analysis with numerical wine performes less optimal in this case\n",
    "\n",
    "\n",
    "4. The reason behind it is that the with classification algorithms, there's higher accuracy with the limitation of the data size, and it doesn't gets limited by the data type. In this case, the wine score isn't really linear and the numerical result doesn't provide a good base for us to use regression or other similar methods to train the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "1. The best performing method is gradient boosting plus bagging, this provides a very high testing score of up to 0.92\n",
    "\n",
    "\n",
    "2. The numerical analysis didn't provide much of a good score, the highest testing score is around 0.6 to 0.7\n",
    "\n",
    "\n",
    "3. Classification algorithms performs best in this circumstances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
